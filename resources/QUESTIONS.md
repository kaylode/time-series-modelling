# Interview questions
Interview questions for the Research Intern - Deep Learning role

## First round (general ML)
I was asked to give a quick presentation about the current work for my Ph.D project. Then they asked follow-up questions:
- What is cross validation? What does it solve?
- How do gradient boosting models work?
- What are the parameters that can be tuned in gradient boosting models ?
- What is the precision, recall metrics in evaluation?
- How do you address overfitting problem?
- How do you address class imbalance problem?
- ...

Then came the coding interview session:
- Classic is palindrome question, but implement in one line of code (using Python)
- Implement the BST, and a function to add new value and one to check if a value exists

## Second round (Time-series)

I was asked to do three case studies on 2 time series datasets. During the presentation, they asked some follow-up questions:
- What are the parameters in ARIMA model (p,d,q) ?
- How do you choose window size for rolling statistics?
- How do you choose thresholding value for anomalies detection ?
- How can you measure anomalies detection metric?
- What is the situation when training loss decreasing but validation loss increasing ?
- Describe some of the techniques to mitigate overfitting: dropout technique, cross validation, early stopping, regularization
- How to address the issue of high dimensionalities?
- Neural-networks based model to solve time series task?
- What parameters can be tuned in training the LSTM ?
- What is the strategy for hyperparameters tuning in Optuna?
- Possible range of learning rate when training LSTM ?
- How to train LSTM on time series data, how to perform forecasting of new values dynamically, meaning, forecasting next arbitrary time steps ?
- Difference between dimensionality reduction vs feature selection in reducing the dimensions of data feature?
